import requests
import json
import os
import time
import re
from bs4 import BeautifulSoup
from discord_webhook import DiscordWebhook, DiscordEmbed
from deep_translator import GoogleTranslator

# ================= ì„¤ì • =================
WEBHOOK_URL = os.environ.get('DISCORD_WEBHOOK_SALES')
if not WEBHOOK_URL:
    WEBHOOK_URL = os.environ.get('DISCORD_WEBHOOK')

if not WEBHOOK_URL:
    print("âš ï¸ [ì˜¤ë¥˜] ì›¹í›… URLì´ ì—†ìŠµë‹ˆë‹¤. Secretsë¥¼ í™•ì¸í•˜ì„¸ìš”!")
    exit()

HISTORY_FILE = "sent_sales.json"

KEYWORDS = [
    "Sale", "Fest", "Festival", "Edition", 
    "ì„¸ì¼", "ì¶•ì œ", "í˜ìŠ¤í‹°ë²Œ", "ëŒ€ì „", "í• ì¸", "ë„¥ìŠ¤íŠ¸ í˜ìŠ¤íŠ¸"
]

EXCLUDE_KEYWORDS = ["Soundtrack", "OST", "Patch", "Hotfix"]
# =======================================

def load_history():
    if os.path.exists(HISTORY_FILE):
        with open(HISTORY_FILE, "r", encoding='utf-8') as f:
            try: return json.load(f)
            except: return []
    return []

def save_history(history):
    with open(HISTORY_FILE, "w", encoding='utf-8') as f:
        if len(history) > 50: history = history[-50:]
        json.dump(history, f, ensure_ascii=False)

def translate_to_korean(text):
    """ì˜ì–´ë¥¼ í•œêµ­ì–´ë¡œ ë²ˆì—­ (í¬ë¡¤ë§ ì‹¤íŒ¨ ì‹œ ë¹„ìƒìš©)"""
    try:
        if len(text) < 2: return text
        # ì´ë¯¸ í•œê¸€ì´ë©´ íŒ¨ìŠ¤
        if any(ord(c) > 12592 for c in text[:20]): return text
        
        translator = GoogleTranslator(source='auto', target='ko')
        # ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ì„œ ë²ˆì—­
        return translator.translate(text[:900]) 
    except:
        return text

def extract_best_link(raw_text):
    """
    ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ 'category', 'sale', 'fests'ê°€ í¬í•¨ëœ 'ì§„ì§œ ìƒì  ë§í¬'ë¥¼ ì°¾ì•„ëƒ…ë‹ˆë‹¤.
    """
    # 1. ê°€ì¥ ìš°ì„ ìˆœìœ„: category, sale, fests ë§í¬
    # [url=https://store.steampowered.com/...] í˜•ì‹ íŒŒì‹±
    patterns = [
        r'store\.steampowered\.com/category/[a-zA-Z0-9_/%]+',
        r'store\.steampowered\.com/sale/[a-zA-Z0-9_/%]+',
        r'store\.steampowered\.com/fests/[a-zA-Z0-9_/%]+'
    ]
    
    for pat in patterns:
        match = re.search(pat, raw_text)
        if match:
            return "https://" + match.group(0).replace('"', '').replace(']', '')
            
    return None

def extract_youtube_id(raw_text):
    """ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ ìœ íŠœë¸Œ ID ì¶”ì¶œ"""
    # [previewyoutube=ID;full]
    match = re.search(r'previewyoutube=([a-zA-Z0-9_-]+)', raw_text)
    if match: return match.group(1)
    return None

def clean_raw_text(text):
    """ì§€ì €ë¶„í•œ íƒœê·¸ ì œê±°"""
    text = re.sub(r'\[previewyoutube=.*?\]\[/previewyoutube\]', '', text)
    text = re.sub(r'\{STEAM_CLAN_IMAGE\}.+?(\s|\[|$)', '', text)
    text = re.sub(r'\[url=.*?\]', '', text)
    text = re.sub(r'\[/url\]', '', text)
    text = re.sub(r'\[.*?\]', '', text)
    text = re.sub(r'\n\s*\n', '\n\n', text).strip()
    return text

def scrape_official_korean(url):
    """ê³µì‹ í•œêµ­ì–´ í˜ì´ì§€ í¬ë¡¤ë§ ì‹œë„"""
    print(f"ğŸ•µï¸â€â™‚ï¸ í¬ë¡¤ë§ ì‹œë„: {url}")
    cookies = {'Steam_Language': 'koreana', 'birthtime': '946684801', 'lastagecheckage': '1-0-2000'}
    headers = {'User-Agent': 'Mozilla/5.0'}
    
    try:
        response = requests.get(url, cookies=cookies, headers=headers, timeout=5)
        if response.status_code != 200: return None
        
        soup = BeautifulSoup(response.text, 'html.parser')
        content_div = soup.select_one('.event_body') or soup.select_one('#news_detail_body')
        
        if content_div:
            return content_div.get_text(separator="\n", strip=True)
    except:
        pass
    return None

def fetch_steam_sales_news():
    print("ğŸ“¡ ìŠ¤íŒ€ ë‰´ìŠ¤ API ìŠ¤ìº” ì¤‘...")
    url = "https://api.steampowered.com/ISteamNews/GetNewsForApp/v2/?appid=593110&count=10&format=json"
    
    try:
        response = requests.get(url, timeout=10)
        data = response.json()
        news_items = data['appnews']['newsitems']
        
        sales_news = []
        for item in news_items:
            title = item['title']
            
            if any(k.lower() in title.lower() for k in EXCLUDE_KEYWORDS): continue
            
            if any(k.lower() in title.lower() for k in KEYWORDS):
                print(f"ğŸ‰ ë°œê²¬: {title}")
                raw_content = item.get('contents', '')
                news_url = item.get('url') or f"https://store.steampowered.com/news/app/593110/view/{item['gid']}"

                # 1. [ë§í¬] ì›ë³¸ ë°ì´í„°ì—ì„œ 'ì§„ì§œ ìƒì  ë§í¬' ì°¾ê¸° (ê°€ì¥ ì¤‘ìš”!)
                real_link = extract_best_link(raw_content)
                if not real_link:
                    real_link = news_url # ëª» ì°¾ìœ¼ë©´ ê·¸ëƒ¥ ë‰´ìŠ¤ ë§í¬ ì‚¬ìš©
                
                # 2. [ì´ë¯¸ì§€] ì›ë³¸ ë°ì´í„°ì—ì„œ ìœ íŠœë¸Œ ID ì°¾ê¸°
                youtube_id = extract_youtube_id(raw_content)
                
                # 3. [í…ìŠ¤íŠ¸] í•œêµ­ì–´ ì„¤ëª… ë§Œë“¤ê¸°
                # (A) í¬ë¡¤ë§ ë¨¼ì € ì‹œë„
                korean_text = scrape_official_korean(news_url)
                
                # (B) í¬ë¡¤ë§ ì‹¤íŒ¨ ì‹œ -> ì›ë³¸ ì²­ì†Œ í›„ ë²ˆì—­ê¸° ê°€ë™
                if not korean_text or len(korean_text) < 10:
                    print("âš ï¸ í¬ë¡¤ë§ ì‹¤íŒ¨/ì°¨ë‹¨ë¨ -> ë²ˆì—­ê¸° ëª¨ë“œë¡œ ì „í™˜")
                    clean_english = clean_raw_text(raw_content)
                    korean_text = translate_to_korean(clean_english)

                # 4. ì œëª©ë„ ë²ˆì—­
                korean_title = translate_to_korean(title)

                # ìµœì¢… ì •ë¦¬ (ê¸¸ì´ ì œí•œ)
                if len(korean_text) > 250: korean_text = korean_text[:250] + "..."

                sales_news.append({
                    "id": item['gid'],
                    "title": korean_title,
                    "desc": korean_text,
                    "link": real_link,  # ì¶”ì¶œí•œ ì§„ì§œ ë§í¬
                    "youtube_id": youtube_id,
                    "date": item['date']
                })
        
        return sales_news[::-1]
        
    except Exception as e:
        print(f"âŒ ì—ëŸ¬: {e}")
        return []

def send_discord_alert(news):
    print(f"ğŸš€ ì „ì†¡: {news['title']}")
    webhook = DiscordWebhook(url=WEBHOOK_URL)
    
    embed = DiscordEmbed(
        title=f"ğŸª {news['title']}",
        description=f"{news['desc']}\n\n[ğŸ‘‰ ì¶•ì œ ìƒì  í˜ì´ì§€ ë°”ë¡œê°€ê¸°]({news['link']})",
        color='FFD700'
    )
    
    if news['youtube_id']:
        embed.set_image(url=f"https://img.youtube.com/vi/{news['youtube_id']}/maxresdefault.jpg")
    else:
        embed.set_thumbnail(url="https://upload.wikimedia.org/wikipedia/commons/thumb/8/83/Steam_icon_logo.svg/2048px-Steam_icon_logo.svg.png")
    
    webhook.add_embed(embed)
    webhook.execute()

def run():
    print("--- ìŠ¤íŒ€ ì„¸ì¼ ë´‡ (í•˜ì´ë¸Œë¦¬ë“œ ë²„ì „) ---")
    history = load_history()
    sales_news = fetch_steam_sales_news()
    
    updated_history = history[:]
    msg_count = 0
    
    for news in sales_news:
        if news['id'] not in history:
            send_discord_alert(news)
            updated_history.append(news['id'])
            msg_count += 1
            time.sleep(1)
            
    if msg_count > 0:
        save_history(updated_history)
        print("ì™„ë£Œ.")
    else:
        print("ìƒˆë¡œìš´ ì†Œì‹ ì—†ìŒ.")

if __name__ == "__main__":
    run()