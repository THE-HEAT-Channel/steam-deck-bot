import requests
import json
import os
import time
import re
from bs4 import BeautifulSoup
from discord_webhook import DiscordWebhook, DiscordEmbed

# ================= ì„¤ì • =================
WEBHOOK_URL = os.environ.get('DISCORD_WEBHOOK_SALES')
if not WEBHOOK_URL:
    WEBHOOK_URL = os.environ.get('DISCORD_WEBHOOK')

if not WEBHOOK_URL:
    print("âš ï¸ [ì˜¤ë¥˜] ì›¹í›… URLì´ ì—†ìŠµë‹ˆë‹¤. Secretsë¥¼ í™•ì¸í•˜ì„¸ìš”!")
    exit()

HISTORY_FILE = "sent_sales.json"

KEYWORDS = [
    "Sale", "Fest", "Festival", "Edition", 
    "ì„¸ì¼", "ì¶•ì œ", "í˜ìŠ¤í‹°ë²Œ", "ëŒ€ì „", "í• ì¸", "ë„¥ìŠ¤íŠ¸ í˜ìŠ¤íŠ¸"
]

EXCLUDE_KEYWORDS = ["Soundtrack", "OST", "Patch", "Hotfix"]
# =======================================

def load_history():
    if os.path.exists(HISTORY_FILE):
        with open(HISTORY_FILE, "r", encoding='utf-8') as f:
            try: return json.load(f)
            except: return []
    return []

def save_history(history):
    with open(HISTORY_FILE, "w", encoding='utf-8') as f:
        if len(history) > 50: history = history[-50:]
        json.dump(history, f, ensure_ascii=False)

def clean_fallback_text(text):
    """í¬ë¡¤ë§ ì‹¤íŒ¨ ì‹œ, ì›ë³¸ í…ìŠ¤íŠ¸ë¼ë„ ìµœëŒ€í•œ ê¹”ë”í•˜ê²Œ ì²­ì†Œ"""
    # ìœ íŠœë¸Œ íƒœê·¸ ì œê±°
    text = re.sub(r'\[previewyoutube=.*?\]\[/previewyoutube\]', '', text)
    # ì´ë¯¸ì§€ íƒœê·¸ ì œê±°
    text = re.sub(r'\{STEAM_CLAN_IMAGE\}.+?(\s|\[|$)', '', text)
    # [url=...] ë§í¬ íƒœê·¸ ì •ë¦¬
    text = re.sub(r'\[url=(.*?)\](.*?)\[/url\]', r'\2', text)
    # ë‚˜ë¨¸ì§€ ëŒ€ê´„í˜¸ íƒœê·¸ ì œê±°
    text = re.sub(r'\[.*?\]', '', text)
    return text.strip()

def scrape_steam_page(url):
    print(f"ğŸ•µï¸â€â™‚ï¸ í˜ì´ì§€ ì ‘ì† ì‹œë„: {url}")
    
    # [í•µì‹¬] ì¿ í‚¤ 3ì¢… ì„¸íŠ¸: í•œêµ­ì–´ ì„¤ì • + ì„±ì¸ ì¸ì¦ í†µê³¼
    cookies = {
        'Steam_Language': 'koreana',
        'birthtime': '946684801', # 2000ë…„ 1ì›” 1ì¼ìƒìœ¼ë¡œ ìœ„ì¥
        'lastagecheckage': '1-0-2000'
    }
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'}
    
    try:
        response = requests.get(url, cookies=cookies, headers=headers, timeout=10)
        if response.status_code != 200: return None
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # 1. ë³¸ë¬¸ ì°¾ê¸° (ì—¬ëŸ¬ í´ë˜ìŠ¤ ì‹œë„)
        content_div = soup.select_one('.event_body') or soup.select_one('#news_detail_body') or soup.select_one('.clan_announcement_body')
        
        if not content_div:
            return None

        # 2. í…ìŠ¤íŠ¸ ì¶”ì¶œ
        text = content_div.get_text(separator="\n", strip=True)
        # ë„ˆë¬´ ê¸´ ë¬¸ë‹¨ ì •ë¦¬
        lines = [line.strip() for line in text.split('\n') if line.strip()]
        clean_text = "\n\n".join(lines[:10]) # ì•ë¶€ë¶„ 10ì¤„ë§Œ ê°€ì ¸ì˜¤ê¸° (ìš”ì•½)

        # 3. ìœ íŠœë¸Œ ID ì°¾ê¸° (iframe ë˜ëŠ” data ì†ì„±)
        youtube_id = None
        # ë°©ë²• A: iframe srcì—ì„œ ì°¾ê¸°
        iframe = content_div.find('iframe', src=re.compile('youtube'))
        if iframe:
            match = re.search(r'embed/([a-zA-Z0-9_-]+)', iframe['src'])
            if match: youtube_id = match.group(1)
        
        # ë°©ë²• B: ìŠ¤íŒ€ ì „ìš© íƒœê·¸ì—ì„œ ì°¾ê¸°
        if not youtube_id:
            yt_div = content_div.find('div', attrs={'data-youtube-video-id': True})
            if yt_div: youtube_id = yt_div['data-youtube-video-id']

        # 4. ìƒì  ë§í¬(Sale Page) ì°¾ê¸°
        store_link = None
        # "ìƒì ", "ì„¸ì¼", "Fest" ë“±ì´ í¬í•¨ëœ ë§í¬ ìš°ì„  ê²€ìƒ‰
        links = content_div.find_all('a', href=True)
        for link in links:
            href = link['href']
            # ì„¸ì¼ í˜ì´ì§€ íŠ¹ì§• (/sale/ ë˜ëŠ” /fests/)
            if "/sale/" in href or "/fests/" in href or "/category/" in href:
                store_link = href
                break 

        return {
            "text": clean_text,
            "youtube_id": youtube_id,
            "store_link": store_link
        }

    except Exception as e:
        print(f"âŒ í¬ë¡¤ë§ ì—ëŸ¬: {e}")
        return None

def fetch_steam_sales_news():
    print("ğŸ“¡ ìŠ¤íŒ€ ë‰´ìŠ¤ API ìŠ¤ìº” ì¤‘...")
    url = "https://api.steampowered.com/ISteamNews/GetNewsForApp/v2/?appid=593110&count=10&format=json"
    
    try:
        response = requests.get(url, timeout=10)
        if response.status_code != 200: return []
        
        data = response.json()
        news_items = data['appnews']['newsitems']
        
        sales_news = []
        for item in news_items:
            title = item['title']
            
            # í‚¤ì›Œë“œ í•„í„°ë§
            if any(k.lower() in title.lower() for k in EXCLUDE_KEYWORDS): continue
            
            if any(k.lower() in title.lower() for k in KEYWORDS):
                print(f"ğŸ‰ íƒ€ê²Ÿ ë°œê²¬: {title}")
                
                news_url = item.get('url', '')
                if not news_url:
                    news_url = f"https://store.steampowered.com/news/app/593110/view/{item['gid']}"
                
                # --- [í¬ë¡¤ë§ ì‹œë„] ---
                scraped = scrape_steam_page(news_url)
                
                # ê¸°ë³¸ê°’ ì„¤ì •
                final_desc = clean_fallback_text(item.get('contents', ''))[:200]
                final_link = news_url
                final_youtube = None
                
                if scraped:
                    print("âœ… í¬ë¡¤ë§ ì„±ê³µ! ë°ì´í„°ë¥¼ ë®ì–´ì”ë‹ˆë‹¤.")
                    if scraped['text']: final_desc = scraped['text'][:300] + "..." # ê¸¸ì´ ì œí•œ
                    if scraped['store_link']: final_link = scraped['store_link']
                    if scraped['youtube_id']: final_youtube = scraped['youtube_id']
                else:
                    print("âš ï¸ í¬ë¡¤ë§ ì‹¤íŒ¨. API ì›ë³¸ ë°ì´í„°ë¥¼ ì²­ì†Œí•´ì„œ ì‚¬ìš©í•©ë‹ˆë‹¤.")

                sales_news.append({
                    "id": item['gid'],
                    "title": title,
                    "desc": final_desc,
                    "link": final_link,
                    "youtube_id": final_youtube,
                    "date": item['date']
                })
        
        return sales_news[::-1]
        
    except Exception as e:
        print(f"âŒ ì „ì²´ ë¡œì§ ì—ëŸ¬: {e}")
        return []

def send_discord_alert(news):
    print(f"ğŸš€ ë””ìŠ¤ì½”ë“œ ì „ì†¡: {news['title']}")
    try:
        webhook = DiscordWebhook(url=WEBHOOK_URL)
        
        # ì œëª©ì— "ì¶•ì œ" ëŠë‚Œ ì¶”ê°€
        embed = DiscordEmbed(
            title=f"ğŸª {news['title']}",
            description=f"{news['desc']}\n\n[ğŸ‘‰ ì¶•ì œ ìƒì  í˜ì´ì§€ ë°”ë¡œê°€ê¸°]({news['link']})",
            color='FFD700'
        )
        
        # ì´ë¯¸ì§€ ì„¤ì •
        if news['youtube_id']:
            # ìœ íŠœë¸Œ ì¸ë„¤ì¼ (ê°€ì¥ ê¹”ë”)
            embed.set_image(url=f"https://img.youtube.com/vi/{news['youtube_id']}/maxresdefault.jpg")
        else:
            # ìŠ¤íŒ€ ë¡œê³ 
            embed.set_thumbnail(url="https://upload.wikimedia.org/wikipedia/commons/thumb/8/83/Steam_icon_logo.svg/2048px-Steam_icon_logo.svg.png")
        
        webhook.add_embed(embed)
        webhook.execute()
    except Exception as e:
        print(f"âŒ ì „ì†¡ ì‹¤íŒ¨: {e}")

def run():
    print("--- ìŠ¤íŒ€ ì„¸ì¼ ë´‡ (ìµœì¢… ìˆ˜ì •íŒ) ---")
    history = load_history()
    sales_news = fetch_steam_sales_news()
    
    updated_history = history[:]
    msg_count = 0
    
    for news in sales_news:
        if news['id'] not in history:
            send_discord_alert(news)
            updated_history.append(news['id'])
            msg_count += 1
            time.sleep(1)
            
    if msg_count > 0:
        save_history(updated_history)
        print("ì „ì†¡ ì™„ë£Œ.")
    else:
        print("ìƒˆë¡œìš´ ì†Œì‹ ì—†ìŒ.")

if __name__ == "__main__":
    run()